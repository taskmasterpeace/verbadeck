# VerbaDeck - Quick Start Guide

## What You Have

A complete voice-driven presentation system with:

- âœ… AssemblyAI Universal-Streaming v3 integration (raw binary PCM16)
- âœ… Node.js WebSocket proxy server
- âœ… React + Vite + shadcn/ui frontend
- âœ… AudioWorklet for mic capture
- âœ… Wake-word arming ("majin twin" / "majin pause")
- âœ… Auto-advance on trigger words (last word of each section)
- âœ… Keyboard controls (P key to pause/resume)
- âœ… Live transcript ticker
- âœ… Playwright visual tests
- âœ… All dependencies installed
- âœ… TypeScript compilation verified

## Run VerbaDeck Now

### Option 1: Run Both Servers (Recommended)

From the project root:

```bash
npm run dev
```

This starts:
- **Server** on http://localhost:3001 (WebSocket proxy)
- **Client** on http://localhost:5173 (Vite dev server)

### Option 2: Run Separately

Terminal 1 (Server):
```bash
cd server
npm run dev
```

Terminal 2 (Client):
```bash
cd client
npm run dev
```

## Usage Flow

1. **Open Browser**: Navigate to http://localhost:5173

2. **Edit Script** (optional): Modify the default pitch script or paste your own

3. **Configure Wake Words** (optional):
   - Default wake word: "majin twin" (arms the system)
   - Default stop word: "majin pause" (pauses advancement)

4. **Start Listening**: Click the "Start Listening" button
   - Grant microphone permissions
   - Wait for green "Connected" indicator

5. **Arm the System**: Say "majin twin"
   - Status changes from "PAUSED" to "ARMED"

6. **Present**: Read your script
   - When you say the **bolded last word** of the current section, it auto-advances
   - Watch the live transcript at the bottom

7. **Pause/Resume**: Press **P** key or say "majin pause"

8. **Stop**: Click "Stop Listening" when done

## What Makes This Special

### Architecture Highlights

1. **AssemblyAI v3 Raw Binary Streaming**:
   - Direct PCM16 audio (not base64)
   - ~50ms chunks for low latency
   - Word-level timestamps and confidence

2. **AudioWorklet Pipeline**:
   - Browser mic â†’ AudioWorklet â†’ PCM16 conversion â†’ WebSocket
   - 16kHz mono, optimized for speech recognition

3. **Server-Side Auth**:
   - API key never exposed to browser
   - Node proxy handles AssemblyAI authentication

4. **State Machine**:
   - ARMED: Listening for trigger words
   - PAUSED: Transcription runs but no advancement
   - Wake/stop words toggle states

5. **Smart Matching**:
   - Regex with suffix tolerance (handles plurals: "moment" / "moments")
   - Debounce prevents double-advance on echoes
   - Word boundary matching

## Test the System

### Run Playwright Tests

```bash
npm test
```

Or with UI mode:

```bash
npm run test:ui
```

### Manual Testing Checklist

- [ ] Script editor visible before streaming
- [ ] Wake/stop words editable
- [ ] "Start Listening" connects (green indicator)
- [ ] Say wake word â†’ status changes to "ARMED"
- [ ] Say trigger word â†’ section advances
- [ ] Press P â†’ toggles ARMED/PAUSED
- [ ] Live transcript shows at bottom
- [ ] Progress bar updates
- [ ] Next section preview visible
- [ ] Section navigation buttons work

## Troubleshooting

### "Cannot connect to WebSocket"

Check server is running:
```bash
curl http://localhost:3001/health
# Should return: {"status":"ok","timestamp":"..."}
```

### "Microphone permission denied"

- Check browser settings â†’ Allow microphone access
- HTTPS required in production (localhost works in dev)

### "Trigger word not detected"

- Verify mode is "ARMED" (green indicator, say wake word)
- Check live transcript to see what AssemblyAI heard
- Speak clearly at normal pace
- Ensure trigger word matches exactly (check console logs)

### TypeScript errors

```bash
cd client
npx tsc --noEmit
```

Should complete with no errors.

## API Key Security Reminder

Your current API key in `.env`:
```
AAI_API_KEY=987aca52da654f01aad3113ecb062169
```

**âš ï¸ IMPORTANT**: After testing, rotate this key:
1. Go to AssemblyAI dashboard
2. Regenerate your API key
3. Update `.env` with new key
4. Never commit `.env` to git (already in `.gitignore`)

## Project Structure Reference

```
verbadeck/
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ server.js           # WebSocket proxy
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ client/
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ audio-processor.js    # AudioWorklet
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/              # shadcn/ui
â”‚   â”‚   â”‚   â”œâ”€â”€ PresenterView.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ScriptEditor.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ StatusBar.tsx
â”‚   â”‚   â”‚   â””â”€â”€ TranscriptTicker.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useAudioStreaming.ts
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ script-parser.ts
â”‚   â”‚   â”‚   â””â”€â”€ utils.ts
â”‚   â”‚   â”œâ”€â”€ App.tsx             # Main app
â”‚   â”‚   â”œâ”€â”€ main.tsx
â”‚   â”‚   â”œâ”€â”€ index.css
â”‚   â”‚   â””â”€â”€ vite-env.d.ts
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ verbadeck.spec.ts      # Playwright tests
â”œâ”€â”€ .env                        # API key (gitignored)
â”œâ”€â”€ README.md                   # Full documentation
â”œâ”€â”€ QUICKSTART.md              # This file
â””â”€â”€ package.json               # Root workspace
```

## Next Steps

### Customize Your Script

1. Edit the default script in `App.tsx` (line 9) or paste directly in the UI
2. Sections are separated by blank lines
3. Last word of each section = trigger word
4. Use Markdown for formatting (bold, italic, etc.)

### Adjust Wake Words

Change default wake/stop words in `App.tsx`:
```typescript
const [wakeWord, setWakeWord] = useState('your custom wake phrase');
const [stopWord, setStopWord] = useState('your custom stop phrase');
```

Or edit them in the UI before starting.

### Tune Sensitivity

In `server/server.js`, adjust AssemblyAI parameters:
```javascript
const aaiParams = new URLSearchParams({
  sample_rate: '16000',
  encoding: 'pcm_s16le',
  format_turns: 'true',
  end_of_turn_confidence_threshold: '0.4',  // Adjust 0.0-1.0
  word_boost: '["your", "important", "words"]'
});
```

### Deploy to Production

See `README.md` "Production Deployment" section for:
- Building client for production
- Deploying server to Node.js hosting
- HTTPS setup (required for microphone access)

---

**You're all set! Run `npm run dev` and start presenting.** ğŸ¤

For full documentation, see `README.md`.
